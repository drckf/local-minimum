---
title: "Weighted Linear Attention as Species Invasion"
author: "Charles Fisher"
date: "2025-04-08"
categories: [research, machine-learning, ecology, attention, lotka-volterra]
image: species-invasion-thumbnail.png
bibliography: weighted-linear-attention.bib
draft: false
---


## TLDR

Weighted linear attention modules are key-value associative memories with potential uses in neural sequence models 
used for tasks such as language modeling. In previous posts, I showed that weighted linear attention can be interpreted 
as an evolving ecological system in which tokens are species and their weights are species abundances. The weights 
evolve under Lotka-Volterra dynamics when optimized via exponentiated gradient descent to minimize the squared 
recall error. This framework provides explicit formulas linking the statistics of the data distribution to ecological 
parameters such as the carrying capacity and interaction coefficients of each token. This post focused on the 
streaming context to show that online updating of an associative memory is equivalent to the invasion of an 
ecosystem by a new species. I use this mapping to derive some novel ecologically inspired attention modules, 
including a closed-form solution for optimal gated linear attention.


## Review of Previous Results

In the previous post [Weighted Linear Attention is Lotka-Volterra Dynamics](
    /posts/weighted-linear-attention-is-lotka-volterra/index.qmd), 
I showed that weighted linear attention modules can be interpreted as ecological systems where tokens are 
species and their weights are species abundances. The weights evolve under Lotka-Volterra dynamics when optimized 
via exponentiated gradient descent to minimize the squared recall error. To briefly review those results,
I focus on a particular form of weighted linear attention module determined by an associative memory matrix,
$$
J = \sum_{l} w_{l} \, \vec{v}_{l} \, \vec{k}_{l}^T \,,
$$
where $l$ denotes the token position, $\vec{v}_l = W_{V} \vec{x}_l \in \mathbb{R}^{d_v}$ is a value vector, 
$\vec{k}_l = W_{K} \vec{x}_l \in \mathbb{R}^{d_k}$ is a key vector, $\vec{x}_l \in \mathbb{R}^{n}$ is a token embedding, 
and $w_l \geq 0$ is the weight of token $l$ in memory. Recall from the memory is simply matrix multiplication,
$$
\tilde{v}_l = J \, \vec{q}_l
$$
where $\vec{q}_l = W_Q \vec{x}_l \in \mathbb{R}^{d_k}$ is a query vector.  The mean squared recall error for a 
batch of tokens $\{ \vec{x}_l \}_{l=1}^L$ is (up to a factor of $1/2$),
$$
C(\vec{w}) = \frac{1}{2 L} \sum_{l=1}^L || \vec{v}_l - J \, \vec{q}_l ||^2 \, .
$$ {#eq-squared-loss}
To learn the weights, the cost function can be minimized using a simple variant of 
exponentiated gradient descent to satisfy the non-negativity constraint [@kivinen1995additive]. 
In the continuous-time limit, this update rule leads to the following differential equation
$$
\frac{d \, w_l}{d \, t} = - w_l \frac{\partial C}{\partial w_l}
$$
that describes the dynamics of the weights under the exponentiated gradient descent.
After a bit of algebra, it's possible to show that the following generalized Lokta-Volterra equation
describes the dynamics of the weights,
$$
\frac{d \, w_l}{d \, t} =  w_l \Big( s_l - \sum_{l'} A_{l, l'} \, w_{l'} \Big) \,,
$$ {#eq-lotka-volterra}
where
$$
\begin{align}
s_l &= \vec{k}_l^T \, \Sigma_{qv} \, \vec{v}_l \,,
\\
A_{l,l'} &= \vec{v}_l^T \, \vec{v}_{l'} \, \vec{k}_{l'}^T \, \Sigma_{qq} \, \vec{k}_{l}
\, ,
\end{align}
$$
$s_l$ is the intrinsic growth rate of token $l$, $A_{l,l'}$ is the interaction coefficient for tokens $l$ and $l'$, 
$\Sigma_{qv}$ is the uncentered query-value correlation matrix, and $\Sigma_{qq}$ is the 
uncentered query-query correlation matrix. 


## Learning Algorithms

The steps for learning the weights of the associative memory are shown as a code snippet below:
```python
def lv_memory(w0, q, k, v, t_max, dt=0.01):
    """Compute memory matrix J from a full batch 
    of tokens using Lotka-Volterra dynamics"""
    Sigma_vv, Sigma_qv, Sigma_qq = compute_correlations(q, v)
    s, A = ecological_params(k, v, Sigma_qv, Sigma_qq)
    w = integrate_lv(w0, s, A, t_max, dt)
    J = torch.einsum('l,li,lj->ij', w, v, k)    
    return J
```
Essentially, learning in full batch mode amounts to calculating the correlation matrices, computing the 
growth rates and interaction coefficients, and then integrating the Lotka-Volterra equations. An example 
with randomly generated synthetic data is shown in @fig-correlation-analysis. The simulations show that there is wide 
variation in the growth rates and the interaction coefficients of the tokens, indicating that certain tokens 
are much more important for the memory than others. Applying exponentiated gradient descent with automatic 
differentiation through the squared reconstruction error results in identical to the dynamics loss curves 
compared to integrating the Lotka-Volterra equations, indicating the derivations are correct. As expected, 
the loss decreases monotonically as the weights converge to a fixed point. 

![Synthetic example data.
    I randomly generated $Q$, $K$, and $V$ matrices with covariance matrices 
    (A) \Sigma_{vv}$, (B) \Sigma_{qq}$, and (C) \Sigma_{qv}$. The resulting growth rates 
    and interaction coefficients are shown in panels D and E. Panel F shows loss curves 
    for the Lotka-Volterra dynamics along with an implementation that directly minimizes 
    the squared loss function through automatic differentiation and exponentiated gradient descent. 
    As expected, the loss curves are identical.
](correlation_analysis.png){#fig-correlation-analysis fig-align="center"}

Storing memories in full-batch mode is interesting from an interpretability standpoint because it allows one to 
understand linearized attention modules through an ecological lens. In practice, however, one is typically more 
interested in storing memories sequentially as new tokens arrive. The naive approach to sequential learning is 
to simply solve the full-batch algorithm again each time a new token arrives. However, this approach is inefficient 
because (i) it's possible to warm-start the integrator from the previous solution and (ii) it's not even necessary to 
update the weights if the new token can't invade the ecosystem.  It is more efficient to use an "invade and adjust" 
algorithm that updates the covariance matrices upon the arrival of a new token, then checks if the new token is able 
to invade the ecosystem and only adjusts the weights if necessary. For the Lotka-Volterra system, a new token $l$ 
cannot invade the ecosystem if
$$
s_l - \sum_{l'=1}^{l-1} A_{l,l'} w_{l'} \leq 0 \,,
$$
in which case $w_l$ should be set to zero. An implementation of an invade and adjust algorithm for sequential memory 
updating is shown in the following code snippet:
```python
def invade_and_adjust(Sigma_vv, Sigma_qv, Sigma_qq, q, v, k, V, K, l, w_prev, t_max=1, dt=0.01):
    """Update memory with new token using online 
    Lotka-Volterra dynamics"""
    # Update statistics
    l = l + 1
    z = (l - 1) / l
    Sigma_vv = z * Sigma_vv + (v @ v.T) / l
    Sigma_qv = z * Sigma_qv + (q @ v.T) / l
    Sigma_qq = z * Sigma_qq + (q @ q.T) / l

    # Check invasion
    s_l = (k.T @ Sigma_qv @ v).item()
    A_l = (v.T @ V.T) * (K @ Sigma_qq @ k).T 
    margin = s_l - (A_l @ w_prev).item()

    # Can't invade
    if margin <= 0:
        return Sigma_vv, Sigma_qv, Sigma_qq, V, K, w_prev, l

    # Can invade
    V_new = torch.cat([V, v[None]], dim=0)
    K_new = torch.cat([K, k[None]], dim=0)
    s, A = compute_ecological_params(K_new, V_new, Sigma_qv, Sigma_qq)

    # Warm start
    eps = torch.tensor([1e-3])
    w_new = torch.cat([w_prev, eps])
    w_new = integrate_lv(w_new, s, A, t_max, dt)

    return Sigma_vv, Sigma_qv, Sigma_qq, V_new, K_new, w_new, l
```

Similar invade and adjust style algorithms have previously been proposed for training support vector machines 
[@mehta2019constrained; @howell2020machine]. These algorithms are exact in the sense that weights are always 
at a fixed point of the dynamical system, provided the system is allowed to reach a equilibrium after a successful 
invasion. This equilibrium point is not necessarily unique if it lies on the boundary, however. Instead, the 
weights of the tokens in the memory will depend on their order of arrival. The dependence of the order of the 
arrival of the species on the composition of the community is a well-known problem in ecology known as the 
historical contingency of community assembly [@fukami2015historical]. 

Although the invade and adjust algorithm is more efficient than solving the Lotka-Volterra from scratch with 
each new token, it requires computation of an $l \times l$ interaction matrix just as with full-batch training. 
Thus, exact algorithms for learning the weights in weighted linear attention are quadratic in the sequence length. 
One of the main goals for exploring different types of linearized attention modules is to develop algorithms that 
are linear in sequence length, therefore it's necessary to introduce some approximations to develop algorithms that 
have the desired scaling properties. 

A simple approximation is to assume that the arrival of a new token $l$ updates the memory matrix as
$$
J_l = \omega_f \, J_{l-1} + \omega_i \vec{v}_l \vec{k}_l^T \,,
$$ {#eq-single-species-lv-memory-update}
where $\omega_f \geq 0$ is a forget gate and $\omega_i \geq 0$ is an input gate [@beck2025xlstm]. 
This assumes that the incoming token $l$ interacts with a fixed memory defined by $J_{l-1}$ and the arrival 
of the new token does not adjust the weights of any previous tokens. Given that this is a type of greedy 
update rule, I refer to this as greedy invasion. With this assumption, the cost function becomes,
$$
\begin{align}
C_l(\omega_i) 
&= \frac{1}{2} \text{Tr}\Big( \Sigma_{vv}^l \Big)
- \omega_f \, s_J + \frac{1}{2} \omega_f^2 \, A_{J,J}
\\
&\quad - \omega_i s_l + \frac{1}{2} \omega_i^2 A_{l,l}
+ \omega_i \, \omega_f \, A_{J,l}
\end{align}
$$
where
$$
\begin{align}
s_{J} &=  \text{Tr}\Big(J_{l-1} \, \Sigma_{qv}^l \Big)
\\
s_{l} &= \vec{k}_l^T \, \Sigma_{qv}^l \, \vec{v}_l 
\\
A_{J, J} &= \text{Tr}\Big(J_{l-1} \, \Sigma_{qq}^l \, J_{l-1}^T \Big)
\\
A_{l, l} &= \vec{v}_l^T \, \vec{v}_l \, \vec{k}_l^T \, \Sigma_{qq}^l \, \vec{k}_l
\\
A_{J, l} &= \vec{v}_l^T \, J_{l-1} \, \Sigma_{qq}^l \, \vec{k}_l
\end{align}
$$
are online estimates for the intrinsic growth rates and interactions. As in the previous section on full-batch 
learning, learning the gates with exponentiated gradient descent in this context leads to a system of two coupled 
ordinary differential equations
$$
\begin{align}
\frac{d \, \omega_f}{d \, t} &= \omega_f \left( s_J - \omega_i A_{J,l} - A_{J,J} \omega_f \right)
\\
\frac{d \, \omega_i}{d \, t} &= \omega_i \left( s_l - \omega_f A_{J,l} - A_{l,l} \omega_i \right)
\end{align}
$$
describing a Lotka-Volterra model with two species. Assuming that the interaction matrix is invertible, 
the unconstrained solution is
$$
\begin{align}
\omega_f^* &= \frac{A_{l,l} \, s_J - A_{J,l} \, s_l}{A_{J,J} \, A_{l,l} - A_{J,l}^2},
\\
\omega_i^* &= \frac{A_{J,J} \, s_l - A_{J,l} \, s_J}{A_{J,J} \, A_{l,l} - A_{J,l}^2}\,.
\end{align}
$$
Taking into account the non-negativity constraints yields
$$
\begin{align}
\omega_f &=
\begin{cases}
\omega_f^*, & \text{if } \omega_i^* > 0, \\[2mm]
\displaystyle \frac{s_J}{A_{J,J}}, & \text{if } \omega_i^* \le 0,
\end{cases}\\[2mm]
\omega_i &=
\begin{cases}
\omega_i^*, & \text{if } \omega_f^* > 0,\\[2mm]
\displaystyle \frac{s_l}{A_{l,l}}, & \text{if } \omega_f^* \le 0,
\end{cases}
\end{align}
$$
which is a closed-form solution for optimal gated linear attention. Alternatively, one could simplify the 
system even further by treating $\omega_f$ as a user specified hyperparameter, in which case 
$$
\omega_i = \max \Big\{0, \frac{s_l - \omega_f A_{J,l}}{A_{l,l}} \Big\} \,,
$$
is the corresponding optimal input gate. In either case, the memory matrix is updated using 
@eq-single-species-lv-memory-update. This greedy invasion update can be interpreted as adapting the 
carrying capacity of the new token in response to ecological pressure—i.e., competition or cooperation—with 
the current contents of memory. The algorithm is shown as a code snippet in the following code snippet:
```python
def greedy_invasion_update(J_prev, v, k, Sigma_qv, Sigma_qq):
    """Lotka-Volterra-inspired gated update 
    to memory matrix"""
    # Compute ecological parameters
    s_J = torch.trace(J_prev @ Sigma_qv)
    s_l = k @ Sigma_qv @ v
    A_JJ = torch.trace(J_prev @ Sigma_qq @ J_prev.T)
    A_ll = (v @ v) * (k @ Sigma_qq @ k)
    A_Jl = v @ J_prev @ Sigma_qq @ k

    # Compute unconstrained gates
    denom = A_JJ * A_ll - A_Jl**2
    omega_f = (A_ll * s_J - A_Jl * s_l) / denom
    omega_i = (A_JJ * s_l - A_Jl * s_J) / denom

    # Apply non-negativity constraints
    if omega_i <= 0:
        omega_f = s_J / A_JJ
        omega_i = 0.0
    elif omega_f <= 0:
        omega_i = s_l / A_ll
        omega_f = 0.0

    # Gated memory update
    J_new = omega_f * J_prev + omega_i * torch.outer(v, k)
    return J_new
```

@fig-fig4 compares the performance of the invade-and-adjust algorithm to greedy invasion, along with a 
baseline of linear attention with equally weighted memories. The invade-and-adjust algorithm has the 
lowest squared error for all token counts, which is expected because it provides a theoretical lower bound. 
Both the invade-and-adjust and greedy invasion algorithms significantly outperform the baseline of equally 
weighted linear attention, with greedy invasion performing slightly worse than invade-and-adjust even though 
the former is linear in sequence length whereas the latter is quadratic. The ecologically inspired updates 
improve over standard linear attention because they do not store all tokens equally and, in fact, do not even 
store all tokens as shown in the bottom panel of @fig-fig4.

![
    Comparison of memory update algorithms. 
    (Top) The ecological methods (Invade-and-Adjust, Greedy Invasion) consistently achieve lower squared
    reconstruction errors (cost) than equally weighted linear attention by selectively updating memory 
    based on invasion fitness. (Bottom) Cumulative number of tokens stored. Ecological updates adaptively 
    reject redundant or non-informative tokens, leading to more compact and efficient memory representations.
](online_memory_cost_comparison.png){#fig-fig4}

Comparing these different variations of weighted linear attention raises some potentially interesting 
questions about the tradeoffs associated with these approaches. Invade-and-adjust provably minimizes 
the squared reconstruction error, but this comes at the cost of complexity that is the square of the 
sequence length. Greedy invasion, by contrast, is fully recurrent and linear in the sequence length but 
it does not have an obvious parallel implementation. Linear attention, of course, is both linear in the 
sequence length and easy to parallelize. The simulations presented here only explore a single realization
of the dynamics of memory formation with some synthetic data and don't constitute a rigorous characterization 
of these tradeoffs, but this mapping to ecological dynamics should provide a rich theoretical framework to 
explore these tradeoffs in future work. 


## Conclusion

In this post, I've show that within a streaming context, online updating of an associative memory is equivalent 
to the invasion of an ecosystem by a new species. And, I used this mapping to derive some novel ecologically 
inspired attention modules, including a closed-form solution for optimal gated linear attention. So far, this 
series of posts has focused on the theory linking attention mechanisms to ecological systems rather than the 
exploration of practical implications, but I speculate that this theoretical framework will be useful for 
developing ecology-inspired approaches to mechanistic interpretability, KV-cache compression, and the design 
of subquadratic attention modules. 

So far, the theoretical framework I've been developing hinges on learning the weights in the weighted linear attention
module in order to minimize the squared reconstruction error of the recalled values. In the next post, I'll show 
that this framework is actually more general and similar dynamical models arise from a wide class of loss functions.

