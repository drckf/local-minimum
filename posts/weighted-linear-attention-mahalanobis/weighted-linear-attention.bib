% miscellaneous

@article{thompson2019aipioneer,
  author = {Thompson, Nicholas},
  title = {An {AI} Pioneer Explains the Evolution of Neural Networks},
  journal = {WIRED},
  year = {2019},
  month = {May},
  url = {https://www.wired.com/story/ai-pioneer-explains-evolution-neural-networks/},
  urldate = {2024-03-02}
},

@book{adams2007hitchhikers,
  author    = {Adams, Douglas},
  title     = {The Hitchhiker's Guide to the Galaxy},
  series    = {Hitchhiker's Guide to the Galaxy},
  volume    = {1},
  publisher = {Random House},
  address   = {New York, NY},
  year      = {2007}
},

@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group UK London}
},

% attention and associative memory

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
},

@article{wang2025test,
  title={Test-time regression: a unifying framework for designing sequence models with associative memory},
  author={Wang, Ke Alexander and Shi, Jiaxin and Fox, Emily B},
  journal={arXiv preprint arXiv:2501.12352},
  year={2025}
},


@article{yang2024parallelizing,
  title={Parallelizing Linear Transformers with the Delta Rule over Sequence Length},
  author={Yang, S. and Wang, B. and Zhang, Y. and Shen, Y. and Kim, Y.},
  journal={NeurIPS},
  year={2024}
},

@article{kohonen1972correlation,
  title={Correlation matrix memories},
  author={Kohonen, Teuvo},
  journal={IEEE transactions on computers},
  volume={100},
  number={4},
  pages={353--359},
  year={1972},
  publisher={IEEE}
},

@article{aksenov2024linear,
  title={Linear transformers with learnable kernel functions are better in-context models},
  author={Aksenov, Yaroslav and Balagansky, Nikita and Vaina, Sofia Maria Lo Cicero and Shaposhnikov, Boris and Gorbatovski, Alexey and Gavrilov, Daniil},
  journal={arXiv preprint arXiv:2402.10644},
  year={2024}
},

@inproceedings{schlag2021linear,
  title={Linear transformers are secretly fast weight programmers},
  author={Schlag, Imanol and Irie, Kazuki and Schmidhuber, J{\"u}rgen},
  booktitle={International conference on machine learning},
  pages={9355--9366},
  year={2021},
  organization={PMLR}
},

@article{schmidhuber1992learning,
  title={Learning to control fast-weight memories: An alternative to dynamic recurrent networks},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={4},
  number={1},
  pages={131--139},
  year={1992},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
},

@article{yang2025parallelizing,
  title={Parallelizing linear transformers with the delta rule over sequence length},
  author={Yang, Songlin and Wang, Bailin and Zhang, Yu and Shen, Yikang and Kim, Yoon},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={115491--115522},
  year={2025}
},

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International conference on machine learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
},

@article{peng2021random,
  title={Random feature attention},
  author={Peng, Hao and Pappas, Nikolaos and Yogatama, Dani and Schwartz, Roy and Smith, Noah A and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2103.02143},
  year={2021}
},

@article{beck2025xlstm,
  title={xlstm: Extended long short-term memory},
  author={Beck, Maximilian and P{\"o}ppel, Korbinian and Spanring, Markus and Auer, Andreas and Prudnikova, Oleksandra and Kopp, Michael and Klambauer, G{\"u}nter and Brandstetter, Johannes and Hochreiter, Sepp},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={107547--107603},
  year={2025}
},

@article{qin2022cosformer,
  title={cosformer: Rethinking softmax in attention},
  author={Qin, Zhen and Sun, Weixuan and Deng, Hui and Li, Dongxu and Wei, Yunshen and Lv, Baohong and Yan, Junjie and Kong, Lingpeng and Zhong, Yiran},
  journal={arXiv preprint arXiv:2202.08791},
  year={2022}
},

@article{kasai2021finetuning,
  title={Finetuning pretrained transformers into rnns},
  author={Kasai, Jungo and Peng, Hao and Zhang, Yizhe and Yogatama, Dani and Ilharco, Gabriel and Pappas, Nikolaos and Mao, Yi and Chen, Weizhu and Smith, Noah A},
  journal={arXiv preprint arXiv:2103.13076},
  year={2021}
},

@article{zhang2024hedgehog,
  title={The hedgehog \& the porcupine: Expressive linear attentions with softmax mimicry},
  author={Zhang, Michael and Bhatia, Kush and Kumbong, Hermann and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2402.04347},
  year={2024}
},

@article{chen2024dijiang,
  title={Dijiang: Efficient large language models through compact kernelization},
  author={Chen, Hanting and Liu, Zhicheng and Wang, Xutao and Tian, Yuchuan and Wang, Yunhe},
  journal={arXiv preprint arXiv:2403.19928},
  year={2024}
},

@article{sun2023retentive,
  title={Retentive network: A successor to transformer for large language models},
  author={Sun, Yutao and Dong, Li and Huang, Shaohan and Ma, Shuming and Xia, Yuqing and Xue, Jilong and Wang, Jianyong and Wei, Furu},
  journal={arXiv preprint arXiv:2307.08621},
  year={2023}
},

@inproceedings{orvieto2023resurrecting,
  title={Resurrecting recurrent neural networks for long sequences},
  author={Orvieto, Antonio and Smith, Samuel L and Gu, Albert and Fernando, Anushan and Gulcehre, Caglar and Pascanu, Razvan and De, Soham},
  booktitle={International Conference on Machine Learning},
  pages={26670--26698},
  year={2023},
  organization={PMLR}
},

@article{katsch2023gateloop,
  title={Gateloop: Fully data-controlled linear recurrence for sequence modeling},
  author={Katsch, Tobias},
  journal={arXiv preprint arXiv:2311.01927},
  year={2023}
},

@article{de2024griffin,
  title={Griffin: Mixing gated linear recurrences with local attention for efficient language models},
  author={De, Soham and Smith, Samuel L and Fernando, Anushan and Botev, Aleksandar and Cristian-Muraru, George and Gu, Albert and Haroun, Ruba and Berrada, Leonard and Chen, Yutian and Srinivasan, Srivatsan and others},
  journal={arXiv preprint arXiv:2402.19427},
  year={2024}
},

@article{qin2024hgrn2,
  title={Hgrn2: Gated linear rnns with state expansion},
  author={Qin, Zhen and Yang, Songlin and Sun, Weixuan and Shen, Xuyang and Li, Dong and Sun, Weigao and Zhong, Yiran},
  journal={arXiv preprint arXiv:2404.07904},
  year={2024}
},

@article{peng2024eagle,
  title={Eagle and finch: Rwkv with matrix-valued states and dynamic recurrence},
  author={Peng, Bo and Goldstein, Daniel and Anthony, Quentin and Albalak, Alon and Alcaide, Eric and Biderman, Stella and Cheah, Eugene and Ferdinan, Teddy and Hou, Haowen and Kazienko, Przemys{\l}aw and others},
  journal={arXiv preprint arXiv:2404.05892},
  volume={3},
  year={2024}
},

@article{yang2023gated,
  title={Gated linear attention transformers with hardware-efficient training},
  author={Yang, Songlin and Wang, Bailin and Shen, Yikang and Panda, Rameswar and Kim, Yoon},
  journal={arXiv preprint arXiv:2312.06635},
  year={2023}
},

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
},

@article{dao2024transformers,
  title={Transformers are ssms: Generalized models and efficient algorithms through structured state space duality},
  author={Dao, Tri and Gu, Albert},
  journal={arXiv preprint arXiv:2405.21060},
  year={2024}
},

@article{liu2024longhorn,
  title={Longhorn: State space models are amortized online learners},
  author={Liu, Bo and Wang, Rui and Wu, Lemeng and Feng, Yihao and Stone, Peter and Liu, Qiang},
  journal={arXiv preprint arXiv:2407.14207},
  year={2024}
},

@article{sun2024learning,
  title={Learning to (learn at test time): Rnns with expressive hidden states},
  author={Sun, Yu and Li, Xinhao and Dalal, Karan and Xu, Jiarui and Vikram, Arjun and Zhang, Genghan and Dubois, Yann and Chen, Xinlei and Wang, Xiaolong and Koyejo, Sanmi and others},
  journal={arXiv preprint arXiv:2407.04620},
  year={2024}
},

@article{yang2024gated,
  title={Gated Delta Networks: Improving Mamba2 with Delta Rule},
  author={Yang, Songlin and Kautz, Jan and Hatamizadeh, Ali},
  journal={arXiv preprint arXiv:2412.06464},
  year={2024}
},

@article{behrouz2024titans,
  title={Titans: Learning to memorize at test time},
  author={Behrouz, Ali and Zhong, Peilin and Mirrokni, Vahab},
  journal={arXiv preprint arXiv:2501.00663},
  year={2024}
},

@book{hinton2014parallel,
  title={Parallel models of associative memory: updated edition},
  author={Hinton, Geoffrey E and Anderson, James A},
  year={2014},
  publisher={Psychology press}
},

% ecology

@article{arthur1969species,
  title={Species packing, and what competition minimizes},
  author={Arthur, Robert Mac},
  journal={Proceedings of the National Academy of Sciences},
  volume={64},
  number={4},
  pages={1369--1371},
  year={1969}
},

@article{macarthur1970species,
  title={Species packing and competitive equilibrium for many species},
  author={MacArthur, Robert},
  journal={Theoretical population biology},
  volume={1},
  number={1},
  pages={1--11},
  year={1970},
  publisher={Elsevier}
},

@article{cui2024houches,
  title={Les houches lectures on community ecology: From niche theory to statistical mechanics},
  author={Cui, Wenping and Marsland III, Robert and Mehta, Pankaj},
  journal={ArXiv},
  pages={arXiv--2403},
  year={2024}
},

@article{wangersky1978lotka,
  title={Lotka-Volterra population models},
  author={Wangersky, Peter J},
  journal={Annual Review of Ecology and Systematics},
  volume={9},
  pages={189--218},
  year={1978},
  publisher={JSTOR}
},

@article{bomze1983lotka,
  title={Lotka-Volterra equation and replicator dynamics: a two-dimensional classification},
  author={Bomze, Immanuel M},
  journal={Biological cybernetics},
  volume={48},
  number={3},
  pages={201--211},
  year={1983},
  publisher={Springer}
},

@article{bomze1995lotka,
  title={Lotka-Volterra equation and replicator dynamics: new issues in classification},
  author={Bomze, Immanuel M},
  journal={Biological cybernetics},
  volume={72},
  number={5},
  pages={447--453},
  year={1995},
  publisher={Springer}
},

@article{schuster1983replicator,
  title={Replicator dynamics},
  author={Schuster, Peter and Sigmund, Karl},
  journal={Journal of theoretical biology},
  volume={100},
  number={3},
  pages={533--538},
  year={1983},
  publisher={Elsevier}
},

@article{sakarchi2025macarthur,
  title={MacArthur’s consumer-resource model: a Rosetta Stone for competitive interactions},
  author={Sakarchi, Jawad and Germain, Rachel M},
  journal={The American Naturalist},
  volume={205},
  number={3},
  pages={000--000},
  year={2025},
  publisher={The University of Chicago Press Chicago, IL}
},

@book{nowak2006evolutionary,
  title={Evolutionary dynamics: exploring the equations of life},
  author={Nowak, Martin A},
  year={2006},
  publisher={Harvard university press}
},

@article{bunin2017ecological,
  title={Ecological communities with Lotka-Volterra dynamics},
  author={Bunin, Guy},
  journal={Physical Review E},
  volume={95},
  number={4},
  pages={042414},
  year={2017},
  publisher={APS}
},

@article{tilman2004niche,
  title={Niche tradeoffs, neutrality, and community structure: a stochastic theory of resource competition, invasion, and community assembly},
  author={Tilman, David},
  journal={Proceedings of the National Academy of Sciences},
  volume={101},
  number={30},
  pages={10854--10861},
  year={2004},
  publisher={National Academy of Sciences}
}.

% machine learning as ecology

@article{mehta2019constrained,
  title={Constrained optimization as ecological dynamics with applications to random quadratic programming in high dimensions},
  author={Mehta, Pankaj and Cui, Wenping and Wang, Ching-Hao and Marsland III, Robert},
  journal={Physical Review E},
  volume={99},
  number={5},
  pages={052111},
  year={2019},
  publisher={APS}
},

@article{howell2020machine,
  title={Machine learning as ecology},
  author={Howell, Owen and Wenping, Cui and Marsland, Robert and Mehta, Pankaj},
  journal={Journal of Physics A: Mathematical and Theoretical},
  volume={53},
  number={33},
  pages={334001},
  year={2020},
  publisher={IOP Publishing}
},

@article{storn1997differential,
  title={Differential evolution--a simple and efficient heuristic for global optimization over continuous spaces},
  author={Storn, Rainer and Price, Kenneth},
  journal={Journal of global optimization},
  volume={11},
  pages={341--359},
  year={1997},
  publisher={Springer}
},

@article{binitha2012survey,
  title={A survey of bio inspired optimization algorithms},
  author={Binitha, S and Sathya, S Siva and others},
  journal={International journal of soft computing and engineering},
  volume={2},
  number={2},
  pages={137--151},
  year={2012},
  publisher={Citeseer}
},

@article{fukami2015historical,
  title={Historical contingency in community assembly: integrating niches, species pools, and priority effects},
  author={Fukami, Tadashi},
  journal={Annual review of ecology, evolution, and systematics},
  volume={46},
  number={1},
  pages={1--23},
  year={2015},
  publisher={Annual Reviews}
},

% portfolio theory

@article{black1992global,
  title={Global portfolio optimization},
  author={Black, Fischer and Litterman, Robert},
  journal={Financial analysts journal},
  volume={48},
  number={5},
  pages={28--43},
  year={1992},
  publisher={Taylor \& Francis}
},

# multiplicative gradient

@inproceedings{kivinen1995additive,
  title={Additive versus exponentiated gradient updates for linear prediction},
  author={Kivinen, Jyrki and Warmuth, Manfred K},
  booktitle={Proceedings of the twenty-seventh annual ACM symposium on Theory of computing},
  pages={209--218},
  year={1995}
},

@inproceedings{ghai2020exponentiated,
  title={Exponentiated gradient meets gradient descent},
  author={Ghai, Udaya and Hazan, Elad and Singer, Yoram},
  booktitle={Algorithmic learning theory},
  pages={386--407},
  year={2020},
  organization={PMLR}
},