<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Charles Fisher">
<meta name="dcterms.date" content="2025-04-08">

<title>Weighted Linear Attention as Species Invasion – Local Minimum</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Local Minimum</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../license.html"> 
<span class="menu-text">License</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/drckf"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Weighted Linear Attention as Species Invasion</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">research</div>
                <div class="quarto-category">machine-learning</div>
                <div class="quarto-category">attention</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Charles Fisher </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 8, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">TLDR</h2>
<p>Weighted linear attention modules are key-value associative memories with potential uses in neural sequence models used for tasks such as language modeling. In previous posts, I showed that weighted linear attention can be interpreted as an evolving ecological system in which tokens are species and their weights are species abundances. The weights evolve under Lotka-Volterra dynamics when optimized via exponentiated gradient descent to minimize the squared recall error. This framework provides explicit formulas linking the statistics of the data distribution to ecological parameters such as the carrying capacity and interaction coefficients of each token. This post focused on the streaming context to show that online updating of an associative memory is equivalent to the invasion of an ecosystem by a new species. I use this mapping to derive some novel ecologically inspired attention modules, including a closed-form solution for optimal gated linear attention.</p>
</section>
<section id="review-of-previous-results" class="level2">
<h2 class="anchored" data-anchor-id="review-of-previous-results">Review of Previous Results</h2>
<p>In the previous post <a href="../../posts/weighted-linear-attention-is-lotka-volterra/index.html">Weighted Linear Attention is Lotka-Volterra Dynamics</a>, I showed that weighted linear attention modules can be interpreted as ecological systems where tokens are species and their weights are species abundances. The weights evolve under Lotka-Volterra dynamics when optimized via exponentiated gradient descent to minimize the squared recall error. To briefly review those results, I focus on a particular form of weighted linear attention module determined by an associative memory matrix, <span class="math display">\[
J = \sum_{l} w_{l} \, \vec{v}_{l} \, \vec{k}_{l}^T \,,
\]</span> where <span class="math inline">\(l\)</span> denotes the token position, <span class="math inline">\(\vec{v}_l = W_{V} \vec{x}_l \in \mathbb{R}^{d_v}\)</span> is a value vector, <span class="math inline">\(\vec{k}_l = W_{K} \vec{x}_l \in \mathbb{R}^{d_k}\)</span> is a key vector, <span class="math inline">\(\vec{x}_l \in \mathbb{R}^{n}\)</span> is a token embedding, and <span class="math inline">\(w_l \geq 0\)</span> is the weight of token <span class="math inline">\(l\)</span> in memory. Recall from the memory is simply matrix multiplication, <span class="math display">\[
\tilde{v}_l = J \, \vec{q}_l
\]</span> where <span class="math inline">\(\vec{q}_l = W_Q \vec{x}_l \in \mathbb{R}^{d_k}\)</span> is a query vector. The mean squared recall error for a batch of tokens <span class="math inline">\(\{ \vec{x}_l \}_{l=1}^L\)</span> is (up to a factor of <span class="math inline">\(1/2\)</span>), <span id="eq-squared-loss"><span class="math display">\[
C(\vec{w}) = \frac{1}{2 L} \sum_{l=1}^L || \vec{v}_l - J \, \vec{q}_l ||^2 \, .
\qquad(1)\]</span></span> To learn the weights, the cost function can be minimized using a simple variant of exponentiated gradient descent to satisfy the non-negativity constraint <span class="citation" data-cites="kivinen1995additive">(<a href="#ref-kivinen1995additive" role="doc-biblioref">Kivinen and Warmuth 1995</a>)</span>. In the continuous-time limit, this update rule leads to the following differential equation <span class="math display">\[
\frac{d \, w_l}{d \, t} = - w_l \frac{\partial C}{\partial w_l}
\]</span> that describes the dynamics of the weights under the exponentiated gradient descent. After a bit of algebra, it’s possible to show that the following generalized Lokta-Volterra equation describes the dynamics of the weights, <span id="eq-lotka-volterra"><span class="math display">\[
\frac{d \, w_l}{d \, t} =  w_l \Big( s_l - \sum_{l'} A_{l, l'} \, w_{l'} \Big) \,,
\qquad(2)\]</span></span> where <span class="math display">\[
\begin{align}
s_l &amp;= \vec{k}_l^T \, \Sigma_{qv} \, \vec{v}_l \,,
\\
A_{l,l'} &amp;= \vec{v}_l^T \, \vec{v}_{l'} \, \vec{k}_{l'}^T \, \Sigma_{qq} \, \vec{k}_{l}
\, ,
\end{align}
\]</span> <span class="math inline">\(s_l\)</span> is the intrinsic growth rate of token <span class="math inline">\(l\)</span>, <span class="math inline">\(A_{l,l'}\)</span> is the interaction coefficient for tokens <span class="math inline">\(l\)</span> and <span class="math inline">\(l'\)</span>, <span class="math inline">\(\Sigma_{qv}\)</span> is the uncentered query-value correlation matrix, and <span class="math inline">\(\Sigma_{qq}\)</span> is the uncentered query-query correlation matrix.</p>
</section>
<section id="learning-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="learning-algorithms">Learning Algorithms</h2>
<p>The steps for learning the weights of the associative memory are shown as a code snippet below:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lv_memory(w0, q, k, v, t_max, dt<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute memory matrix J from a full batch </span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">    of tokens using Lotka-Volterra dynamics"""</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    Sigma_vv, Sigma_qv, Sigma_qq <span class="op">=</span> compute_correlations(q, v)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    s, A <span class="op">=</span> ecological_params(k, v, Sigma_qv, Sigma_qq)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> integrate_lv(w0, s, A, t_max, dt)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    J <span class="op">=</span> torch.einsum(<span class="st">'l,li,lj-&gt;ij'</span>, w, v, k)    </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> J</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Essentially, learning in full batch mode amounts to calculating the correlation matrices, computing the growth rates and interaction coefficients, and then integrating the Lotka-Volterra equations. An example with randomly generated synthetic data is shown in <a href="#fig-correlation-analysis" class="quarto-xref">Figure&nbsp;1</a>. The simulations show that there is wide variation in the growth rates and the interaction coefficients of the tokens, indicating that certain tokens are much more important for the memory than others. Applying exponentiated gradient descent with automatic differentiation through the squared reconstruction error results in identical to the dynamics loss curves compared to integrating the Lotka-Volterra equations, indicating the derivations are correct. As expected, the loss decreases monotonically as the weights converge to a fixed point.</p>
<div id="fig-correlation-analysis" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-correlation-analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="correlation_analysis.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-correlation-analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Synthetic example data. I randomly generated <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(V\)</span> matrices with covariance matrices (A) <em>{vv}<span class="math inline">\(, (B) \Sigma_{qq}\)</span>, and (C) </em>{qv}$. The resulting growth rates and interaction coefficients are shown in panels D and E. Panel F shows loss curves for the Lotka-Volterra dynamics along with an implementation that directly minimizes the squared loss function through automatic differentiation and exponentiated gradient descent. As expected, the loss curves are identical.
</figcaption>
</figure>
</div>
<p>Storing memories in full-batch mode is interesting from an interpretability standpoint because it allows one to understand linearized attention modules through an ecological lens. In practice, however, one is typically more interested in storing memories sequentially as new tokens arrive. The naive approach to sequential learning is to simply solve the full-batch algorithm again each time a new token arrives. However, this approach is inefficient because (i) it’s possible to warm-start the integrator from the previous solution and (ii) it’s not even necessary to update the weights if the new token can’t invade the ecosystem. It is more efficient to use an “invade and adjust” algorithm that updates the covariance matrices upon the arrival of a new token, then checks if the new token is able to invade the ecosystem and only adjusts the weights if necessary. For the Lotka-Volterra system, a new token <span class="math inline">\(l\)</span> cannot invade the ecosystem if <span class="math display">\[
s_l - \sum_{l'=1}^{l-1} A_{l,l'} w_{l'} \leq 0 \,,
\]</span> in which case <span class="math inline">\(w_l\)</span> should be set to zero. An implementation of an invade and adjust algorithm for sequential memory updating is shown in the following code snippet:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> invade_and_adjust(Sigma_vv, Sigma_qv, Sigma_qq, q, v, k, V, K, l, w_prev, t_max<span class="op">=</span><span class="dv">1</span>, dt<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Update memory with new token using online </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Lotka-Volterra dynamics"""</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update statistics</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    l <span class="op">=</span> l <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> (l <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> l</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    Sigma_vv <span class="op">=</span> z <span class="op">*</span> Sigma_vv <span class="op">+</span> (v <span class="op">@</span> v.T) <span class="op">/</span> l</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    Sigma_qv <span class="op">=</span> z <span class="op">*</span> Sigma_qv <span class="op">+</span> (q <span class="op">@</span> v.T) <span class="op">/</span> l</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    Sigma_qq <span class="op">=</span> z <span class="op">*</span> Sigma_qq <span class="op">+</span> (q <span class="op">@</span> q.T) <span class="op">/</span> l</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check invasion</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    s_l <span class="op">=</span> (k.T <span class="op">@</span> Sigma_qv <span class="op">@</span> v).item()</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    A_l <span class="op">=</span> (v.T <span class="op">@</span> V.T) <span class="op">*</span> (K <span class="op">@</span> Sigma_qq <span class="op">@</span> k).T </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    margin <span class="op">=</span> s_l <span class="op">-</span> (A_l <span class="op">@</span> w_prev).item()</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Can't invade</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> margin <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> Sigma_vv, Sigma_qv, Sigma_qq, V, K, w_prev, l</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Can invade</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    V_new <span class="op">=</span> torch.cat([V, v[<span class="va">None</span>]], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    K_new <span class="op">=</span> torch.cat([K, k[<span class="va">None</span>]], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    s, A <span class="op">=</span> compute_ecological_params(K_new, V_new, Sigma_qv, Sigma_qq)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Warm start</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    eps <span class="op">=</span> torch.tensor([<span class="fl">1e-3</span>])</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    w_new <span class="op">=</span> torch.cat([w_prev, eps])</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    w_new <span class="op">=</span> integrate_lv(w_new, s, A, t_max, dt)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Sigma_vv, Sigma_qv, Sigma_qq, V_new, K_new, w_new, l</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Similar invade and adjust style algorithms have previously been proposed for training support vector machines <span class="citation" data-cites="mehta2019constrained howell2020machine">(<a href="#ref-mehta2019constrained" role="doc-biblioref">Mehta et al. 2019</a>; <a href="#ref-howell2020machine" role="doc-biblioref">Howell et al. 2020</a>)</span>. These algorithms are exact in the sense that weights are always at a fixed point of the dynamical system, provided the system is allowed to reach a equilibrium after a successful invasion. This equilibrium point is not necessarily unique if it lies on the boundary, however. Instead, the weights of the tokens in the memory will depend on their order of arrival. The dependence of the order of the arrival of the species on the composition of the community is a well-known problem in ecology known as the historical contingency of community assembly <span class="citation" data-cites="fukami2015historical">(<a href="#ref-fukami2015historical" role="doc-biblioref">Fukami 2015</a>)</span>.</p>
<p>Although the invade and adjust algorithm is more efficient than solving the Lotka-Volterra from scratch with each new token, it requires computation of an <span class="math inline">\(l \times l\)</span> interaction matrix just as with full-batch training. Thus, exact algorithms for learning the weights in weighted linear attention are quadratic in the sequence length. One of the main goals for exploring different types of linearized attention modules is to develop algorithms that are linear in sequence length, therefore it’s necessary to introduce some approximations to develop algorithms that have the desired scaling properties.</p>
<p>A simple approximation is to assume that the arrival of a new token <span class="math inline">\(l\)</span> updates the memory matrix as <span id="eq-single-species-lv-memory-update"><span class="math display">\[
J_l = \omega_f \, J_{l-1} + \omega_i \vec{v}_l \vec{k}_l^T \,,
\qquad(3)\]</span></span> where <span class="math inline">\(\omega_f \geq 0\)</span> is a forget gate and <span class="math inline">\(\omega_i \geq 0\)</span> is an input gate <span class="citation" data-cites="beck2025xlstm">(<a href="#ref-beck2025xlstm" role="doc-biblioref">Beck et al. 2025</a>)</span>. This assumes that the incoming token <span class="math inline">\(l\)</span> interacts with a fixed memory defined by <span class="math inline">\(J_{l-1}\)</span> and the arrival of the new token does not adjust the weights of any previous tokens. Given that this is a type of greedy update rule, I refer to this as greedy invasion. With this assumption, the cost function becomes, <span class="math display">\[
\begin{align}
C_l(\omega_i)
&amp;= \frac{1}{2} \text{Tr}\Big( \Sigma_{vv}^l \Big)
- \omega_f \, s_J + \frac{1}{2} \omega_f^2 \, A_{J,J}
\\
&amp;\quad - \omega_i s_l + \frac{1}{2} \omega_i^2 A_{l,l}
+ \omega_i \, \omega_f \, A_{J,l}
\end{align}
\]</span> where <span class="math display">\[
\begin{align}
s_{J} &amp;=  \text{Tr}\Big(J_{l-1} \, \Sigma_{qv}^l \Big)
\\
s_{l} &amp;= \vec{k}_l^T \, \Sigma_{qv}^l \, \vec{v}_l
\\
A_{J, J} &amp;= \text{Tr}\Big(J_{l-1} \, \Sigma_{qq}^l \, J_{l-1}^T \Big)
\\
A_{l, l} &amp;= \vec{v}_l^T \, \vec{v}_l \, \vec{k}_l^T \, \Sigma_{qq}^l \, \vec{k}_l
\\
A_{J, l} &amp;= \vec{v}_l^T \, J_{l-1} \, \Sigma_{qq}^l \, \vec{k}_l
\end{align}
\]</span> are online estimates for the intrinsic growth rates and interactions. As in the previous section on full-batch learning, learning the gates with exponentiated gradient descent in this context leads to a system of two coupled ordinary differential equations <span class="math display">\[
\begin{align}
\frac{d \, \omega_f}{d \, t} &amp;= \omega_f \left( s_J - \omega_i A_{J,l} - A_{J,J} \omega_f \right)
\\
\frac{d \, \omega_i}{d \, t} &amp;= \omega_i \left( s_l - \omega_f A_{J,l} - A_{l,l} \omega_i \right)
\end{align}
\]</span> describing a Lotka-Volterra model with two species. Assuming that the interaction matrix is invertible, the unconstrained solution is <span class="math display">\[
\begin{align}
\omega_f^* &amp;= \frac{A_{l,l} \, s_J - A_{J,l} \, s_l}{A_{J,J} \, A_{l,l} - A_{J,l}^2},
\\
\omega_i^* &amp;= \frac{A_{J,J} \, s_l - A_{J,l} \, s_J}{A_{J,J} \, A_{l,l} - A_{J,l}^2}\,.
\end{align}
\]</span> Taking into account the non-negativity constraints yields <span class="math display">\[
\begin{align}
\omega_f &amp;=
\begin{cases}
\omega_f^*, &amp; \text{if } \omega_i^* &gt; 0, \\[2mm]
\displaystyle \frac{s_J}{A_{J,J}}, &amp; \text{if } \omega_i^* \le 0,
\end{cases}\\[2mm]
\omega_i &amp;=
\begin{cases}
\omega_i^*, &amp; \text{if } \omega_f^* &gt; 0,\\[2mm]
\displaystyle \frac{s_l}{A_{l,l}}, &amp; \text{if } \omega_f^* \le 0,
\end{cases}
\end{align}
\]</span> which is a closed-form solution for optimal gated linear attention. Alternatively, one could simplify the system even further by treating <span class="math inline">\(\omega_f\)</span> as a user specified hyperparameter, in which case <span class="math display">\[
\omega_i = \max \Big\{0, \frac{s_l - \omega_f A_{J,l}}{A_{l,l}} \Big\} \,,
\]</span> is the corresponding optimal input gate. In either case, the memory matrix is updated using <a href="#eq-single-species-lv-memory-update" class="quarto-xref">Equation&nbsp;3</a>. This greedy invasion update can be interpreted as adapting the carrying capacity of the new token in response to ecological pressure—i.e., competition or cooperation—with the current contents of memory. The algorithm is shown as a code snippet in the following code snippet:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> greedy_invasion_update(J_prev, v, k, Sigma_qv, Sigma_qq):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Lotka-Volterra-inspired gated update </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">    to memory matrix"""</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute ecological parameters</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    s_J <span class="op">=</span> torch.trace(J_prev <span class="op">@</span> Sigma_qv)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    s_l <span class="op">=</span> k <span class="op">@</span> Sigma_qv <span class="op">@</span> v</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    A_JJ <span class="op">=</span> torch.trace(J_prev <span class="op">@</span> Sigma_qq <span class="op">@</span> J_prev.T)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    A_ll <span class="op">=</span> (v <span class="op">@</span> v) <span class="op">*</span> (k <span class="op">@</span> Sigma_qq <span class="op">@</span> k)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    A_Jl <span class="op">=</span> v <span class="op">@</span> J_prev <span class="op">@</span> Sigma_qq <span class="op">@</span> k</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute unconstrained gates</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    denom <span class="op">=</span> A_JJ <span class="op">*</span> A_ll <span class="op">-</span> A_Jl<span class="op">**</span><span class="dv">2</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    omega_f <span class="op">=</span> (A_ll <span class="op">*</span> s_J <span class="op">-</span> A_Jl <span class="op">*</span> s_l) <span class="op">/</span> denom</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    omega_i <span class="op">=</span> (A_JJ <span class="op">*</span> s_l <span class="op">-</span> A_Jl <span class="op">*</span> s_J) <span class="op">/</span> denom</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply non-negativity constraints</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> omega_i <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        omega_f <span class="op">=</span> s_J <span class="op">/</span> A_JJ</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        omega_i <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> omega_f <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        omega_i <span class="op">=</span> s_l <span class="op">/</span> A_ll</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        omega_f <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gated memory update</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    J_new <span class="op">=</span> omega_f <span class="op">*</span> J_prev <span class="op">+</span> omega_i <span class="op">*</span> torch.outer(v, k)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> J_new</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><a href="#fig-fig4" class="quarto-xref">Figure&nbsp;2</a> compares the performance of the invade-and-adjust algorithm to greedy invasion, along with a baseline of linear attention with equally weighted memories. The invade-and-adjust algorithm has the lowest squared error for all token counts, which is expected because it provides a theoretical lower bound. Both the invade-and-adjust and greedy invasion algorithms significantly outperform the baseline of equally weighted linear attention, with greedy invasion performing slightly worse than invade-and-adjust even though the former is linear in sequence length whereas the latter is quadratic. The ecologically inspired updates improve over standard linear attention because they do not store all tokens equally and, in fact, do not even store all tokens as shown in the bottom panel of <a href="#fig-fig4" class="quarto-xref">Figure&nbsp;2</a>.</p>
<div id="fig-fig4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="online_memory_cost_comparison.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Comparison of memory update algorithms. (Top) The ecological methods (Invade-and-Adjust, Greedy Invasion) consistently achieve lower squared reconstruction errors (cost) than equally weighted linear attention by selectively updating memory based on invasion fitness. (Bottom) Cumulative number of tokens stored. Ecological updates adaptively reject redundant or non-informative tokens, leading to more compact and efficient memory representations.
</figcaption>
</figure>
</div>
<p>Comparing these different variations of weighted linear attention raises some potentially interesting questions about the tradeoffs associated with these approaches. Invade-and-adjust provably minimizes the squared reconstruction error, but this comes at the cost of complexity that is the square of the sequence length. Greedy invasion, by contrast, is fully recurrent and linear in the sequence length but it does not have an obvious parallel implementation. Linear attention, of course, is both linear in the sequence length and easy to parallelize. The simulations presented here only explore a single realization of the dynamics of memory formation with some synthetic data and don’t constitute a rigorous characterization of these tradeoffs, but this mapping to ecological dynamics should provide a rich theoretical framework to explore these tradeoffs in future work.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this post, I’ve show that within a streaming context, online updating of an associative memory is equivalent to the invasion of an ecosystem by a new species. And, I used this mapping to derive some novel ecologically inspired attention modules, including a closed-form solution for optimal gated linear attention. So far, this series of posts has focused on the theory linking attention mechanisms to ecological systems rather than the exploration of practical implications, but I speculate that this theoretical framework will be useful for developing ecology-inspired approaches to mechanistic interpretability, KV-cache compression, and the design of subquadratic attention modules.</p>
<p>So far, the theoretical framework I’ve been developing hinges on learning the weights in the weighted linear attention module in order to minimize the squared reconstruction error of the recalled values. In the next post, I’ll show that this framework is actually more general and similar dynamical models arise from a wide class of loss functions.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-beck2025xlstm" class="csl-entry" role="listitem">
Beck, Maximilian, Korbinian Pöppel, Markus Spanring, Andreas Auer, Oleksandra Prudnikova, Michael Kopp, Günter Klambauer, Johannes Brandstetter, and Sepp Hochreiter. 2025. <span>“Xlstm: Extended Long Short-Term Memory.”</span> <em>Advances in Neural Information Processing Systems</em> 37: 107547–603.
</div>
<div id="ref-fukami2015historical" class="csl-entry" role="listitem">
Fukami, Tadashi. 2015. <span>“Historical Contingency in Community Assembly: Integrating Niches, Species Pools, and Priority Effects.”</span> <em>Annual Review of Ecology, Evolution, and Systematics</em> 46 (1): 1–23.
</div>
<div id="ref-howell2020machine" class="csl-entry" role="listitem">
Howell, Owen, Cui Wenping, Robert Marsland, and Pankaj Mehta. 2020. <span>“Machine Learning as Ecology.”</span> <em>Journal of Physics A: Mathematical and Theoretical</em> 53 (33): 334001.
</div>
<div id="ref-kivinen1995additive" class="csl-entry" role="listitem">
Kivinen, Jyrki, and Manfred K Warmuth. 1995. <span>“Additive Versus Exponentiated Gradient Updates for Linear Prediction.”</span> In <em>Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing</em>, 209–18.
</div>
<div id="ref-mehta2019constrained" class="csl-entry" role="listitem">
Mehta, Pankaj, Wenping Cui, Ching-Hao Wang, and Robert Marsland III. 2019. <span>“Constrained Optimization as Ecological Dynamics with Applications to Random Quadratic Programming in High Dimensions.”</span> <em>Physical Review E</em> 99 (5): 052111.
</div>
</div></section></div></main> <!-- /main -->
<hr style="margin: 2rem 0; border: 0; border-top: 2px solid #ccc;">

<h2>Subscribe to Updates</h2>

<p>Enter your email below if you want to subscribe to be automatically notified of new posts.</p>

<form action="https://assets.mailerlite.com/jsonp/1441877/forms/151220238201914872/subscribe" method="post" target="_blank" style="max-width: 500px; margin-bottom: 30px;">
  <div style="display: flex; margin-bottom: 10px;">
    <input type="email" name="fields[email]" placeholder="Your email address" required="" style="flex-grow: 1; padding: 8px; margin-right: 10px; border: 1px solid #ccc; border-radius: 4px;">
    <button type="submit" style="background-color: #1677be; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;">
      Subscribe
    </button>
  </div>
  <p style="font-size: 0.8em; color: #666;">
    We respect your privacy. Unsubscribe at any time.
  </p>
  <input type="hidden" name="ml-submit" value="1">
  <input type="hidden" name="anticsrf" value="true">
</form>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    const form = document.querySelector('form[action*="mailerlite"]');
    if (form) {
      form.addEventListener('submit', function(e) {
        e.preventDefault();
        const email = form.querySelector('input[name="fields[email]"]').value;
        const formData = new FormData();
        formData.append('fields[email]', email);
        formData.append('ml-submit', '1');
        formData.append('anticsrf', 'true');
        
        fetch(form.action, {
          method: 'POST',
          body: formData,
          mode: 'no-cors'
        })
        .then(() => {
          // Show success message
          form.innerHTML = '<p style="color: #1677be; font-weight: bold;">Thank you! You\'ve successfully subscribed to Local Minimum updates.</p>';
        });
      });
    }
  });
</script>

<div class="license-footer" style="margin-top: 2rem; padding-top: 1rem; border-top: 1px solid #eee; font-size: 0.8em; color: #666;">
  © 2025 Charles Fisher. This work is licensed under a <a href="../../license.html">Creative Commons Attribution 4.0 International License</a>.
</div>

<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/drckf\.github\.io\/local-minimum\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="drckf/local-minimum" data-repo-id="R_kgDOOVGEfA" data-category="Announcements" data-category-id="DIC_kwDOOVGEfM4Co189" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="light">
</div> <!-- /content -->




</body></html>